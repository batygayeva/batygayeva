import nltk

nltk.download('stopwords')
nltk.download('punkt')

from urllib.request import urlopen
from bs4 import BeautifulSoup

n = str(input('Введите ссылку: '))

url = "https://" + n + "/"
html = urlopen(url).read()
soup = BeautifulSoup(html)

# удалить все элементы скрипта и стиля
for script in soup(["script", "style"]):
    script.extract()    # извлечение данных

text = soup.get_text()

from nltk.corpus import stopwords
stop_words = set(stopwords.words('russian','kazakh'))

#токенизировать набор данных
from nltk.tokenize import sent_tokenize, word_tokenize
words = word_tokenize(text)

# удаляет знаки препинания и цифры
wordsFiltered = [word.lower() for word in words if word.isalpha()]

# удалить стоп-слова из набора токенизированных данных
filtered_words = [word for word in wordsFiltered if word not in stopwords.words('russian','kazakh')]

from wordcloud import WordCloud
import matplotlib.pyplot as plt
wc = WordCloud(max_words=1000, margin=10, background_color='white',
scale=3, relative_scaling = 0.5, width=1000, height=300,
random_state=1).generate(' '.join(filtered_words))
plt.figure(figsize=(200,100))
plt.imshow(wc)
plt.axis("off")
plt.show()
#wc.to_file("/wordcloud.png")